{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DeepLearning_for_rcc_data.ipynb","version":"0.3.2","provenance":[{"file_id":"1H0HttORuwOS8OW8Ym-mXTeG2DOgWQGTW","timestamp":1559620830021},{"file_id":"13qMdgTw_Jjdvt7qjxDddq4mZm721GEm_","timestamp":1559616271897},{"file_id":"1X6mbnNpaFMxMmVM3wD2moQ0NxEARddCC","timestamp":1558134029115}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"KbgY7tFcSUyg","colab_type":"text"},"source":["##Data Loading/Preprocessing \n"]},{"cell_type":"code","metadata":{"id":"ZEEsNEM_yX01","colab_type":"code","outputId":"2af34259-02f7-4b39-c9a5-e460481f0b9e","executionInfo":{"status":"ok","timestamp":1559626100556,"user_tz":420,"elapsed":26116,"user":{"displayName":"Keane Gonzalez","photoUrl":"https://lh6.googleusercontent.com/-VAefjoKCMb4/AAAAAAAAAAI/AAAAAAAAgUA/yzSCHC4ctv8/s64/photo.jpg","userId":"05145815574107174413"}},"colab":{"base_uri":"https://localhost:8080/","height":1278}},"source":["import tensorflow as tf\n","tf.compat.v1.disable_eager_execution()\n","#tf.enable_eager_execution()\n","import tempfile\n","import zipfile\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from google.colab import drive #for loading gdrive data\n","from google.colab import files\n","\n","import imageio\n","\n","\n","\n","######KERAS TRY\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.layers import Activation, Dropout, Flatten, Dense\n","from keras import backend as K\n","\n","\n","num_classes=2 #for images of numbers, options from 0-9, so 10 classes\n","\n","batch_size=300  #usually, higher batches give better results\n","\n","epochs=5 #number of times to go over the full data set\n","\n","img_rows,img_cols=128,128 #28,28  #size of input images to go into the network\n","\n","input_shape=(img_rows,img_cols,1)  #1 is the number of channels, 2D image with \n","                                   #one channel\n","\n","#\n","# Load data from google drive\n","#\n","\n","drive.mount('/content/gdrive')\n","\n","#uploaded = files.upload()\n","\n","\n","\n","\n","#\n","# This section might be easier to use, but for now doesn't open correctly\n","#\n","fname = '/content/gdrive/My Drive/RCC_DATA/RENAL_CANCER_PROJECT_INPUTS/ONCO_IMAGE_DATA_128x128/10024-0054_2006-12-22/rgb0074.png'\n","\n","#with open('/content/gdrive/My Drive/RCC_DATA/RENAL_CANCER_PROJECT_INPUTS/RCC_IMAGE_DATA_128x128/10024-0011_2013_05_19/rgb0013.png', 'r') as f:\n","with open('/content/gdrive/My Drive/RCC_DATA/RENAL_CANCER_PROJECT_INPUTS/ONCO_IMAGE_DATA_128x128/10024-0054_2006-12-22/rgb0074.png', 'r') as f:\n","  im = imageio.imread(fname)\n","  print(im.shape)\n","  #f.write('Hello Google Drive!')\n","#!cat /content/gdrive/My\\ Drive/RCC_DATA/RENAL_CANCER_PROJECT_INPUTS/RCC_IMAGE_DATA_128x128/10024-0511_2013_06_21/rgb0075.png\n","#!cat /content/gdrive/My\\ Drive/foo.txt\n","  \n","  \n","  \n","  \n","  \n","\n","####################\n","#Keras setup\n","# dimensions of our images.\n","img_width, img_height = 128,128\n","\n","train_data_dir = '/content/gdrive/My Drive/data/train'\n","validation_data_dir = '/content/gdrive/My Drive/data/validation'\n","nb_train_samples = 100\n","nb_validation_samples = 50\n","epochs = 5 #50\n","batch_size = 30\n","#############################################################\n","\n","\n","if K.image_data_format() == 'channels_first':\n","    input_shape = (3, img_width, img_height)\n","else:\n","    input_shape = (img_width, img_height, 3) #typical RGB setup\n","    \n","print('input_shape type is ',type(input_shape))\n","print('length of input_shape is ',len(input_shape))\n","\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Flatten())\n","model.add(Dense(64))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(1))\n","model.add(Activation('sigmoid'))\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])\n","\n","\n","\n","\n","\n","\n","\n","##########################\n","\n","# this is the augmentation configuration we will use for training\n","train_datagen = ImageDataGenerator(\n","    rescale=1. / 255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True)\n","\n","\n","# this is the augmentation configuration we will use for testing:\n","# only rescaling\n","test_datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","\n","#\n","# Pull data from gdrive areas\n","#\n","\n","print('-----train generation ------\\n')\n","train_generator = train_datagen.flow_from_directory(\n","    train_data_dir,\n","    target_size=(img_width, img_height),\n","    batch_size=batch_size,\n","    class_mode='binary')\n","\n","print('------validation generation ---\\n')\n","validation_generator = test_datagen.flow_from_directory(\n","    validation_data_dir,\n","    target_size=(img_width, img_height),\n","    batch_size=batch_size,\n","    class_mode='binary')\n","\n","\n","\n","print('fit generator')\n","model.fit_generator(\n","    train_generator,\n","    steps_per_epoch=nb_train_samples // batch_size,\n","    epochs=epochs,\n","    validation_data=validation_generator,\n","    validation_steps=nb_validation_samples // batch_size)\n","\n","model.save_weights('first_try.h5')\n","\n","\n","model.summary()\n","\n","\n","##############################\n","\n","model.compile(\n","    loss=tf.keras.losses.categorical_crossentropy,\n","    optimizer='adam',\n","    metrics=['accuracy'])\n","\n","#compile requires 3 main arguments, adam optimizer is the standard\n","print('metrics names: \\n',model.metrics_names)\n","\n","# fine-tune the model\n","model.fit_generator(\n","    train_generator,\n","    samples_per_epoch=nb_train_samples,\n","    epochs=epochs,\n","    validation_data=validation_generator,\n","    nb_val_samples=nb_validation_samples)\n","\n","\n","#model.fit(x_train, y_train,\n","#          batch_size=batch_size,\n","#          epochs=epochs,\n","#          verbose=1,\n","#          validation_data=(x_test, y_test))\n","\n","#score = model.evaluate(x_test, y_test, verbose=0)\n","\n","#from medium.com examples\n","STEP_SIZE_TEST=train_generator.n//train_generator.batch_size\n","train_generator.reset()\n","pred=model.predict_generator(train_generator,\n","steps=STEP_SIZE_TEST,\n","verbose=1)\n","\n","predicted_class_indices=np.argmax(pred,axis=1)\n","\n","labels = (train_generator.class_indices)\n","labels = dict((v,k) for k,v in labels.items())\n","predictions = [labels[k] for k in predicted_class_indices]\n","for xx in predictions:\n","  if (xx == 'rcc'):\n","    print('rcc found\\n')\n","###################################################\n","\n","#score = model.evaluate(train_generator, validation_generator, verbose=0)\n","\n","#print('Test loss:', score[0])\n","#print('Test accuracy:', score[1])\n","\n"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","(128, 128, 3)\n","input_shape type is  <class 'tuple'>\n","length of input_shape is  3\n","-----train generation ------\n","\n","Found 436 images belonging to 2 classes.\n","------validation generation ---\n","\n","Found 271 images belonging to 1 classes.\n","fit generator\n","Epoch 1/5\n","3/3 [==============================] - 3s 1s/step - loss: 0.8194 - acc: 0.5333 - val_loss: 0.3451 - val_acc: 1.0000\n","Epoch 2/5\n","3/3 [==============================] - 0s 24ms/step - loss: 0.6940 - acc: 0.6556 - val_loss: 0.5888 - val_acc: 1.0000\n","Epoch 3/5\n","3/3 [==============================] - 0s 26ms/step - loss: 0.6797 - acc: 0.5667 - val_loss: 0.5715 - val_acc: 1.0000\n","Epoch 4/5\n","3/3 [==============================] - 0s 26ms/step - loss: 0.6809 - acc: 0.5778 - val_loss: 0.3790 - val_acc: 1.0000\n","Epoch 5/5\n","3/3 [==============================] - 0s 22ms/step - loss: 0.6307 - acc: 0.7078 - val_loss: 0.5166 - val_acc: 1.0000\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_40 (Conv2D)           (None, 126, 126, 32)      896       \n","_________________________________________________________________\n","activation_66 (Activation)   (None, 126, 126, 32)      0         \n","_________________________________________________________________\n","max_pooling2d_40 (MaxPooling (None, 63, 63, 32)        0         \n","_________________________________________________________________\n","conv2d_41 (Conv2D)           (None, 61, 61, 32)        9248      \n","_________________________________________________________________\n","activation_67 (Activation)   (None, 61, 61, 32)        0         \n","_________________________________________________________________\n","max_pooling2d_41 (MaxPooling (None, 30, 30, 32)        0         \n","_________________________________________________________________\n","conv2d_42 (Conv2D)           (None, 28, 28, 64)        18496     \n","_________________________________________________________________\n","activation_68 (Activation)   (None, 28, 28, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_42 (MaxPooling (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","flatten_14 (Flatten)         (None, 12544)             0         \n","_________________________________________________________________\n","dense_27 (Dense)             (None, 64)                802880    \n","_________________________________________________________________\n","activation_69 (Activation)   (None, 64)                0         \n","_________________________________________________________________\n","dropout_14 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","dense_28 (Dense)             (None, 1)                 65        \n","_________________________________________________________________\n","activation_70 (Activation)   (None, 1)                 0         \n","=================================================================\n","Total params: 831,585\n","Trainable params: 831,585\n","Non-trainable params: 0\n","_________________________________________________________________\n","metrics names: \n"," ['loss', 'acc']\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:181: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:181: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., epochs=5, validation_data=<keras_pre..., steps_per_epoch=3, validation_steps=50)`\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/5\n","3/3 [==============================] - 6s 2s/step - loss: 4.6359e-08 - acc: 0.6333 - val_loss: 0.0000e+00 - val_acc: 1.0000\n","Epoch 2/5\n","3/3 [==============================] - 3s 1s/step - loss: 4.5035e-08 - acc: 0.6778 - val_loss: 0.0000e+00 - val_acc: 1.0000\n","Epoch 3/5\n","3/3 [==============================] - 3s 1s/step - loss: 4.2386e-08 - acc: 0.6667 - val_loss: 0.0000e+00 - val_acc: 1.0000\n","Epoch 4/5\n","3/3 [==============================] - 3s 969ms/step - loss: 4.5035e-08 - acc: 0.6333 - val_loss: 0.0000e+00 - val_acc: 1.0000\n","Epoch 5/5\n","3/3 [==============================] - 3s 967ms/step - loss: 3.3959e-08 - acc: 0.7340 - val_loss: 0.0000e+00 - val_acc: 1.0000\n","14/14 [==============================] - 2s 163ms/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pAOk3gqirn2L","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"5a089a56-2683-48fc-d843-c57885d08114","executionInfo":{"status":"ok","timestamp":1559625987429,"user_tz":420,"elapsed":301,"user":{"displayName":"Keane Gonzalez","photoUrl":"https://lh6.googleusercontent.com/-VAefjoKCMb4/AAAAAAAAAAI/AAAAAAAAgUA/yzSCHC4ctv8/s64/photo.jpg","userId":"05145815574107174413"}}},"source":["a = pred > 0.5\n","for counter,xx in enumerate(a):\n","  if(xx =='True'):\n","      print('found one @',counter)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"dXS21kftYA-7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WVI95hCeQn-r","colab_type":"code","outputId":"38241835-82b7-4e19-dc4a-78777f7dd67b","executionInfo":{"status":"ok","timestamp":1558327301536,"user_tz":420,"elapsed":2302,"user":{"displayName":"Keane Gonzalez","photoUrl":"https://lh6.googleusercontent.com/-VAefjoKCMb4/AAAAAAAAAAI/AAAAAAAAgUA/yzSCHC4ctv8/s64/photo.jpg","userId":"05145815574107174413"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#built-in function convert labels to one-hut encoded, only want binary values\n","#example, 5 =0 0 0 0 0 1 0 0 0     for digits 0 - 9\n","#           MSB              LSB\n","y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n","y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n","\n","print(y_train.shape)\n","#print(y_train[0,0,0,0,1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(60000, 10)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4QgheiAqSo0L","colab_type":"text"},"source":["##Create the CNN architecture\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"kghRXTOWSxLK","colab_type":"code","outputId":"e0533fcb-3530-4790-a5ea-0baddd4d3846","executionInfo":{"status":"ok","timestamp":1558327303290,"user_tz":420,"elapsed":4036,"user":{"displayName":"Keane Gonzalez","photoUrl":"https://lh6.googleusercontent.com/-VAefjoKCMb4/AAAAAAAAAAI/AAAAAAAAgUA/yzSCHC4ctv8/s64/photo.jpg","userId":"05145815574107174413"}},"colab":{"base_uri":"https://localhost:8080/","height":564}},"source":["l = tf.keras.layers\n","\n","#32 filters, k = 5\n","#input image is 28x28x1\n","model = tf.keras.Sequential([\n","    l.Conv2D(32, 5, padding='same', activation='relu', input_shape=input_shape),\n","    #28x28x32 after Conv2D\n","    l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n","    l.BatchNormalization(),\n","    l.Conv2D(64,5,padding='same',activation='relu',input_shape=input_shape),\n","    #14x14x64 going into maxpool,7x7x64 out    \n","    l.MaxPooling2D((2, 2), (2, 2), padding='same'),   \n","    #7x7x64 out of maxpool, now flatten into an array\n","    l.Flatten(),\n","    #each element is now fully connected to the dense neurons\n","    l.Dense(1024,activation='relu'), #number of neurons as input\n","    l.Dropout(0.4), #drop 40%, usually 0.2 to 0.4\n","    l.Dense(10,activation='softmax'), #\n","])\n","\n","#for maxpooling2d, care about kernel size of 2 and stride of 2. This shrinks \n","#the size of the image by 2. No filters are changed. There are NO learnable\n","#parameters in a maxpool operation\n","\n","#Batchnorm stablizes the network, usually required for most models\n","#want to flatten the 7x7x64 into a vector of size (7x7x64) elements\n","\n","#output of flatten goes into hidden neurons, which are fully connected. These\n","#fully connected layers are connected to each element of the input. Each neuron\n","# is w(x) + b. Number of neurons in layer depends on task and testing\n","#next layer is softmax layer, which has the same neurons as the number of labels\n","#expected. Each output node is the probability that the image info is of that\n","#label type\n","\n","#dropout is only used during training, not testing\n","\n","\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 28, 28, 32)        832       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","batch_normalization_v1 (Batc (None, 14, 14, 32)        128       \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 14, 14, 64)        51264     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 3136)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 1024)              3212288   \n","_________________________________________________________________\n","dropout (Dropout)            (None, 1024)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                10250     \n","=================================================================\n","Total params: 3,274,762\n","Trainable params: 3,274,698\n","Non-trainable params: 64\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ysgKEUfES41X","colab_type":"text"},"source":["##Compile and Train the model"]},{"cell_type":"code","metadata":{"id":"D6oBQbLhS-8b","colab_type":"code","outputId":"827d30ce-cc75-4743-d52f-92307244897c","executionInfo":{"status":"ok","timestamp":1558327384353,"user_tz":420,"elapsed":24965,"user":{"displayName":"Keane Gonzalez","photoUrl":"https://lh6.googleusercontent.com/-VAefjoKCMb4/AAAAAAAAAAI/AAAAAAAAgUA/yzSCHC4ctv8/s64/photo.jpg","userId":"05145815574107174413"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["model.compile(\n","    loss=tf.keras.losses.categorical_crossentropy,\n","    optimizer='adam',\n","    metrics=['accuracy'])\n","\n","#compile requires 3 main arguments, adam optimizer is the standard\n","\n","model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/5\n","60000/60000 [==============================] - 5s 80us/sample - loss: 0.0258 - acc: 0.9915 - val_loss: 0.0308 - val_acc: 0.9910\n","Epoch 2/5\n","60000/60000 [==============================] - 4s 73us/sample - loss: 0.0223 - acc: 0.9931 - val_loss: 0.0260 - val_acc: 0.9928\n","Epoch 3/5\n","60000/60000 [==============================] - 4s 73us/sample - loss: 0.0177 - acc: 0.9944 - val_loss: 0.0309 - val_acc: 0.9900\n","Epoch 4/5\n","60000/60000 [==============================] - 5s 79us/sample - loss: 0.0139 - acc: 0.9956 - val_loss: 0.0305 - val_acc: 0.9912\n","Epoch 5/5\n","60000/60000 [==============================] - 5s 79us/sample - loss: 0.0107 - acc: 0.9967 - val_loss: 0.0299 - val_acc: 0.9923\n","Test loss: 0.02993167931542116\n","Test accuracy: 0.9923\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hsNzkG2-bR_2","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}